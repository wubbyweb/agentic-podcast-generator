{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🤖 Agentic Podcast Generator Interactive\n",
    "\n",
    "Welcome to the **Agentic Podcast Generator** interactive tutorial! This notebook will guide you through understanding and using this intelligent multi-agent system that creates LinkedIn posts and voice dialog scripts from any topic.\n",
    "\n",
    "## What is the Agentic Podcast Generator?\n",
    "\n",
    "The Agentic Podcast Generator is an AI-powered system that uses multiple specialized agents working together to:\n",
    "- Research topics comprehensively\n",
    "- Generate SEO-optimized keywords and hashtags\n",
    "- Create engaging LinkedIn posts\n",
    "- Convert posts into conversational voice scripts\n",
    "\n",
    "The system follows a hierarchical agent architecture where a **Master Agent** orchestrates several **Sub-agents**, each specializing in different tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📁 Step 1: Explore the Project Structure\n",
    "\n",
    "Let's start by examining the project structure to understand how the code is organized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/rj/Programs/agentic-podcast-generator\n",
      "\n",
      "Project structure:\n",
      "📄 .env\n",
      "📄 .env.example\n",
      "📁 .git/\n",
      "📄 .gitignore\n",
      "📁 .opencode/\n",
      "📁 .pytest_cache/\n",
      "📁 .venv/\n",
      "📄 README.md\n",
      "📁 __pycache__/\n",
      "📄 agentic_podcast_generator_tutorial.ipynb\n",
      "📄 agentic_system.db\n",
      "📁 agents/\n",
      "   📄 agents/__init__.py\n",
      "   📁 agents/__pycache__/\n",
      "   📄 agents/base_agent.py\n",
      "   📄 agents/master_agent.py\n",
      "   📁 agents/sub_agents/\n",
      "📁 config/\n",
      "   📄 config/__init__.py\n",
      "   📁 config/__pycache__/\n",
      "   📄 config/settings.py\n",
      "📁 database/\n",
      "   📄 database/__init__.py\n",
      "   📁 database/__pycache__/\n",
      "   📄 database/connection.py\n",
      "   📄 database/models.py\n",
      "📄 main.py\n",
      "📄 project_structure.md\n",
      "📄 pyproject.toml\n",
      "📄 requirements.txt\n",
      "📄 sequence.md\n",
      "📁 services/\n",
      "   📄 services/__init__.py\n",
      "   📁 services/__pycache__/\n",
      "   📄 services/logger.py\n",
      "   📄 services/openrouter_client.py\n",
      "   📄 services/search_api.py\n",
      "   📄 services/web_scraper.py\n",
      "📄 system_architecture.md\n",
      "📄 technical_specifications.md\n",
      "📄 test_system.py\n",
      "📁 tests/\n",
      "📁 utils/\n",
      "   📄 utils/__init__.py\n",
      "   📁 utils/__pycache__/\n",
      "   📄 utils/communication.py\n",
      "   📄 utils/retry.py\n",
      "   📄 utils/validators.py\n",
      "📄 uv.lock\n"
     ]
    }
   ],
   "source": [
    "# Let's explore the project structure\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = Path.cwd()\n",
    "print(f\"Current directory: {current_dir}\")\n",
    "\n",
    "# List all files and directories\n",
    "print(\"\\nProject structure:\")\n",
    "for item in sorted(current_dir.iterdir()):\n",
    "    if item.is_file():\n",
    "        print(f\"📄 {item.name}\")\n",
    "    else:\n",
    "        print(f\"📁 {item.name}/\")\n",
    "        # Show contents of key directories\n",
    "        if item.name in ['agents', 'config', 'database', 'services', 'utils']:\n",
    "            for subitem in sorted(item.iterdir()):\n",
    "                if subitem.is_file():\n",
    "                    print(f\"   📄 {item.name}/{subitem.name}\")\n",
    "                else:\n",
    "                    print(f\"   📁 {item.name}/{subitem.name}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏗️ Step 2: Understand the System Architecture\n",
    "\n",
    "The system consists of the following components:\n",
    "\n",
    "### 1. Master Agent (Coordinator)\n",
    "- **Role**: Orchestrates the entire workflow\n",
    "- **Responsibilities**:\n",
    "  - Manages parallel execution of sub-agents\n",
    "  - Handles sequential processing\n",
    "  - Logs all interactions\n",
    "- **Important Note**: Does NOT use GPT-5 for analysis (despite some outdated documentation)\n",
    "\n",
    "### 2. Perplexity AI Research (sonar model)\n",
    "- **Role**: Performs comprehensive research\n",
    "- **Capabilities**:\n",
    "  - Uses Perplexity AI for deep research\n",
    "  - Provides current facts, trends, and insights\n",
    "  - Validates information credibility\n",
    "- **Note**: This replaces the originally planned GPT-5 analysis\n",
    "\n",
    "### 3. Keyword Generator (Gemini 2.0 Flash)\n",
    "- **Role**: Generates SEO-optimized keywords and hashtags\n",
    "- **Model**: google/gemini-2.0-flash-001\n",
    "- **Output**: Keywords, hashtags, and relevance scores\n",
    "\n",
    "### 4. Post Generator (Grok-3 Mini)\n",
    "- **Role**: Creates engaging LinkedIn posts\n",
    "- **Model**: xai/grok-3-mini\n",
    "- **Style**: Casual, professional, and engaging\n",
    "\n",
    "### 5. Voice Dialog Generator (Grok-3 Mini)\n",
    "- **Role**: Converts posts to conversational voice scripts\n",
    "- **Model**: xai/grok-3-mini\n",
    "- **Output**: Natural, podcast-ready dialog\n",
    "\n",
    "### Database Layer\n",
    "- **SQLite Database**: Persistent storage for sessions, logs, and results\n",
    "- **Tables**: sessions, agent_logs, research_results, keywords, generated_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine the main entry point\n",
    "print(\"=== MAIN.PY - Entry Point ===\")\n",
    "with open('main.py', 'r') as f:\n",
    "    content = f.read()\n",
    "    # Show the first 50 lines to understand the structure\n",
    "    print(content[:1000] + \"...\")\n",
    "    \n",
    "print(\"\\n=== MASTER AGENT - Core Orchestrator ===\")\n",
    "with open('agents/master_agent.py', 'r') as f:\n",
    "    content = f.read()\n",
    "    # Show the class definition and key methods\n",
    "    lines = content.split('\\n')\n",
    "    for i, line in enumerate(lines[:40]):\n",
    "        print(f\"{i+1:2d}: {line}\")\n",
    "    print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📋 Step 3: Understand the Workflow\n",
    "\n",
    "Here's how the system processes a topic:\n",
    "\n",
    "1. **User Input**: Topic provided via command line\n",
    "2. **Research Phase**: Perplexity AI (sonar model) researches the topic\n",
    "3. **Parallel Processing**:\n",
    "   - Keyword Generator creates keywords/hashtags\n",
    "   - Post Generator creates LinkedIn content\n",
    "   - Voice Dialog Generator creates podcast script\n",
    "4. **Output**: Formatted results with all generated content\n",
    "5. **Logging**: All interactions stored in database\n",
    "\n",
    "### Data Flow Diagram\n",
    "```\n",
    "Topic Input\n",
    "    ↓\n",
    "Perplexity AI Research (sonar)\n",
    "    ↓\n",
    "Parallel Execution:\n",
    "├── Keyword Generation (Gemini 2.0 Flash)\n",
    "├── Post Generation (Grok-3 Mini)\n",
    "└── Voice Script Generation (Grok-3 Mini)\n",
    "    ↓\n",
    "Final Output + Database Logging\n",
    "```\n",
    "\n",
    "### Important Clarification: GPT-5 References\n",
    "\n",
    "**GPT-5 is NOT used anywhere in the actual running application.** Despite some outdated references in documentation and tests, the system uses:\n",
    "- **Perplexity AI (sonar)** for research\n",
    "- **Gemini 2.0 Flash** for keywords\n",
    "- **Grok-3 Mini** for posts and voice scripts\n",
    "\n",
    "The original design planned to use GPT-5 for topic analysis, but the implementation uses Perplexity AI instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine the workflow in the master agent\n",
    "import re\n",
    "\n",
    "with open('agents/master_agent.py', 'r') as f:\n",
    "    content = f.read()\n",
    "    \n",
    "# Find the main processing method\n",
    "pattern = r'async def process_topic_with_research.*?return \\{'\n",
    "match = re.search(pattern, content, re.DOTALL)\n",
    "if match:\n",
    "    print(\"=== MAIN PROCESSING WORKFLOW ===\")\n",
    "    workflow_code = match.group(0)\n",
    "    lines = workflow_code.split('\\n')\n",
    "    for i, line in enumerate(lines[:30]):\n",
    "        print(f\"{i+1:2d}: {line}\")\n",
    "    print(\"...\")\n",
    "    \n",
    "# Show parallel execution part\n",
    "parallel_pattern = r'# Execute all sub-agents concurrently.*?return_exceptions=True'\n",
    "match = re.search(parallel_pattern, content, re.DOTALL)\n",
    "if match:\n",
    "    print(\"\\n=== PARALLEL EXECUTION ===\")\n",
    "    print(match.group(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🛠️ Step 4: Check Environment Setup\n",
    "\n",
    "Let's check if the environment is properly set up for running the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Python version\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Check if required packages are available\n",
    "required_packages = ['asyncio', 'json', 'pathlib', 'dotenv']\n",
    "missing_packages = []\n",
    "\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"✓ {package} is available\")\n",
    "    except ImportError:\n",
    "        missing_packages.append(package)\n",
    "        print(f\"✗ {package} is missing\")\n",
    "\n",
    "if missing_packages:\n",
    "    print(f\"\\nMissing packages: {missing_packages}\")\n",
    "    print(\"Run: pip install -r requirements.txt\")\n",
    "else:\n",
    "    print(\"\\n✓ All basic packages are available!\")\n",
    "\n",
    "# Check if .env file exists\n",
    "from pathlib import Path\n",
    "env_file = Path('.env')\n",
    "if env_file.exists():\n",
    "    print(\"✓ .env file exists\")\n",
    "else:\n",
    "    print(\"✗ .env file missing - copy from .env.example\")\n",
    "\n",
    "# Check if database exists\n",
    "db_file = Path('agentic_system.db')\n",
    "if db_file.exists():\n",
    "    print(\"✓ Database file exists\")\n",
    "else:\n",
    "    print(\"✗ Database file missing - will be created on first run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚙️ Step 5: Examine Configuration\n",
    "\n",
    "Let's look at the configuration system to understand how the application is configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the configuration\n",
    "print(\"=== CONFIGURATION SETTINGS ===\")\n",
    "try:\n",
    "    from config.settings import config\n",
    "    print(f\"Log level: {config.log_level}\")\n",
    "    print(f\"Database URL: {config.database_url}\")\n",
    "    print(f\"OpenRouter API Key: {'Set' if config.openrouter_api_key else 'Not set'}\")\n",
    "    \n",
    "    # Show model configurations\n",
    "    print(\"\\nModel configurations:\")\n",
    "    for agent, model_config in config.models.items():\n",
    "        print(f\"  {agent}: {model_config.name}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Configuration error: {e}\")\n",
    "    print(\"Make sure .env file is properly configured\")\n",
    "\n",
    "# Show the .env.example file\n",
    "print(\"\\n=== .ENV.EXAMPLE ===\")\n",
    "try:\n",
    "    with open('.env.example', 'r') as f:\n",
    "        print(f.read())\n",
    "except FileNotFoundError:\n",
    "    print(\"No .env.example file found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Step 6: Examine the Agent Classes\n",
    "\n",
    "Let's look at the base agent class and one of the sub-agents to understand the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the base agent class\n",
    "print(\"=== BASE AGENT CLASS ===\")\n",
    "with open('agents/base_agent.py', 'r') as f:\n",
    "    content = f.read()\n",
    "    lines = content.split('\\n')\n",
    "    for i, line in enumerate(lines[:40]):\n",
    "        print(f\"{i+1:2d}: {line}\")\n",
    "    print(\"...\")\n",
    "\n",
    "# Examine a sub-agent\n",
    "print(\"\\n=== KEYWORD GENERATOR AGENT ===\")\n",
    "with open('agents/sub_agents/keyword_generator.py', 'r') as f:\n",
    "    content = f.read()\n",
    "    # Show the execute method\n",
    "    lines = content.split('\\n')\n",
    "    in_execute = False\n",
    "    for i, line in enumerate(lines):\n",
    "        if 'async def execute' in line:\n",
    "            in_execute = True\n",
    "            print(f\"\\nExecute method (line {i+1}):\")\n",
    "        if in_execute:\n",
    "            print(f\"{i+1:3d}: {line}\")\n",
    "            if line.strip() == '':\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💾 Step 7: Understand the Database Schema\n",
    "\n",
    "Let's examine the database models to understand how data is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the database models\n",
    "print(\"=== DATABASE MODELS ===\")\n",
    "with open('database/models.py', 'r') as f:\n",
    "    content = f.read()\n",
    "    lines = content.split('\\n')\n",
    "    \n",
    "# Show the main model classes\n",
    "in_class = False\n",
    "current_class = \"\"\n",
    "for i, line in enumerate(lines):\n",
    "    if line.startswith('class '):\n",
    "        if current_class:\n",
    "            print(f\"\\n{current_class} class:\")\n",
    "        current_class = line.split('(')[0].replace('class ', '')\n",
    "        in_class = True\n",
    "        print(f\"\\n{current_class} (line {i+1}):\")\n",
    "    elif in_class and line.strip().startswith('__tablename__'):\n",
    "        print(f\"  Table: {line.split('=')[1].strip().strip('\"')}\")\n",
    "    elif in_class and line.strip().startswith('id ='):\n",
    "        print(f\"  Primary key: id\")\n",
    "        break  # Just show the first few lines of each class\n",
    "\n",
    "# Show database initialization\n",
    "print(\"\\n=== DATABASE INITIALIZATION ===\")\n",
    "with open('database/connection.py', 'r') as f:\n",
    "    content = f.read()\n",
    "    lines = content.split('\\n')\n",
    "    for i, line in enumerate(lines[:30]):\n",
    "        print(f\"{i+1:2d}: {line}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Step 8: Try Basic Usage\n",
    "\n",
    "Let's try running the system with a simple example. **Note**: This requires a valid OpenRouter API key in your .env file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we can import the main components\n",
    "print(\"Testing imports...\")\n",
    "try:\n",
    "    from agents.master_agent import MasterAgent\n",
    "    from config.settings import config\n",
    "    print(\"✓ Core imports successful\")\n",
    "    \n",
    "    # Check if API key is configured\n",
    "    if config.openrouter_api_key:\n",
    "        print(\"✓ API key is configured\")\n",
    "        \n",
    "        # Try a simple test (commented out to avoid API calls)\n",
    "        print(\"\\nTo run the system, use:\")\n",
    "        print(\"python main.py \\\"Your Topic Here\\\"\")\n",
    "        \n",
    "    else:\n",
    "        print(\"✗ API key not configured\")\n",
    "        print(\"Please set OPENROUTER_API_KEY in your .env file\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"✗ Import error: {e}\")\n",
    "    print(\"Make sure dependencies are installed: pip install -r requirements.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧪 Step 9: Run Tests\n",
    "\n",
    "Let's run the test suite to see if everything is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the tests\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"Running tests...\")\n",
    "try:\n",
    "    result = subprocess.run([sys.executable, '-m', 'pytest', 'tests/', '-v'], \n",
    "                          capture_output=True, text=True, timeout=60)\n",
    "    \n",
    "    print(\"STDOUT:\")\n",
    "    print(result.stdout)\n",
    "    \n",
    "    if result.stderr:\n",
    "        print(\"STDERR:\")\n",
    "        print(result.stderr)\n",
    "        \n",
    "    print(f\"\\nReturn code: {result.returncode}\")\n",
    "    \n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"Tests timed out\")\n",
    "except FileNotFoundError:\n",
    "    print(\"pytest not found. Install with: pip install pytest\")\n",
    "except Exception as e:\n",
    "    print(f\"Error running tests: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Step 10: Examine Database Contents\n",
    "\n",
    "If the database exists, let's examine its contents to see previous runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine database contents\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "db_path = Path('agentic_system.db')\n",
    "if db_path.exists():\n",
    "    print(\"=== DATABASE CONTENTS ===\")\n",
    "    \n",
    "    conn = sqlite3.connect(str(db_path))\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Show all tables\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    print(f\"Tables: {[table[0] for table in tables]}\")\n",
    "    \n",
    "    # Show sessions\n",
    "    cursor.execute(\"SELECT COUNT(*) FROM sessions\")\n",
    "    session_count = cursor.fetchone()[0]\n",
    "    print(f\"Total sessions: {session_count}\")\n",
    "    \n",
    "    if session_count > 0:\n",
    "        cursor.execute(\"SELECT id, topic, status, created_at FROM sessions ORDER BY created_at DESC LIMIT 5\")\n",
    "        sessions = cursor.fetchall()\n",
    "        print(\"\\nRecent sessions:\")\n",
    "        for session in sessions:\n",
    "            print(f\"  ID: {session[0]}, Topic: {session[1]}, Status: {session[2]}, Created: {session[3]}\")\n",
    "    \n",
    "    # Show agent logs count\n",
    "    cursor.execute(\"SELECT COUNT(*) FROM agent_logs\")\n",
    "    log_count = cursor.fetchone()[0]\n",
    "    print(f\"\\nTotal agent logs: {log_count}\")\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "else:\n",
    "    print(\"Database does not exist yet. Run the system to create it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Step 11: Check for Outdated GPT-5 References\n",
    "\n",
    "Let's search for any outdated references to GPT-5 in the codebase to understand what needs to be updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for GPT-5 references in the codebase\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def search_gpt5_references():\n",
    "    \"\"\"Search for GPT-5 references in the codebase\"\"\"\n",
    "    gpt5_files = []\n",
    "    \n",
    "    # Walk through all files\n",
    "    for root, dirs, files in os.walk('.'):\n",
    "        # Skip .git, __pycache__, etc.\n",
    "        dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['__pycache__', 'node_modules']]\n",
    "        \n",
    "        for file in files:\n",
    "            if file.endswith(('.py', '.md', '.ipynb', '.txt')):\n",
    "                filepath = Path(root) / file\n",
    "                try:\n",
    "                    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                        content = f.read()\n",
    "                        if re.search(r'GPT-5|gpt-5', content):\n",
    "                            # Count occurrences\n",
    "                            count = re.findall(r'GPT-5|gpt-5', content)\n",
    "                            gpt5_files.append((str(filepath), len(count)))\n",
    "                except Exception as e:\n",
    "                    pass  # Skip files that can't be read\n",
    "    \n",
    "    return gpt5_files\n",
    "\n",
    "# Search for GPT-5 references\n",
    "gpt5_references = search_gpt5_references()\n",
    "\n",
    "print(\"=== GPT-5 REFERENCES FOUND ===\")\n",
    "if gpt5_references:\n",
    "    print(f\"Found {len(gpt5_references)} files with GPT-5 references:\")\n",
    "    for filepath, count in gpt5_references:\n",
    "        print(f\"  {filepath}: {count} reference(s)\")\n",
    "        \n",
    "    print(\"\\n=== IMPORTANT NOTE ===\")\n",
    "    print(\"GPT-5 is NOT used in the actual running application!\")\n",
    "    print(\"These references are in:\")\n",
    "    print(\"- Documentation files (outdated)\")\n",
    "    print(\"- Test files (expecting old defaults)\")\n",
    "    print(\"- Example code (speculative)\")\n",
    "    \n",
    "    print(\"\\n=== ACTUAL MODELS USED ===\")\n",
    "    print(\"Research: sonar (Perplexity AI)\")\n",
    "    print(\"Keywords: google/gemini-2.0-flash-001\")\n",
    "    print(\"Posts: xai/grok-3-mini\")\n",
    "    print(\"Voice: xai/grok-3-mini\")\n",
    "    \n",
    "else:\n",
    "    print(\"No GPT-5 references found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 Step 12: Examine Services and Utilities\n",
    "\n",
    "Let's look at the supporting services that make the system work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the services\n",
    "print(\"=== OPENROUTER CLIENT ===\")\n",
    "with open('services/openrouter_client.py', 'r') as f:\n",
    "    content = f.read()\n",
    "    lines = content.split('\\n')\n",
    "    for i, line in enumerate(lines[:30]):\n",
    "        print(f\"{i+1:2d}: {line}\")\n",
    "    print(\"...\")\n",
    "\n",
    "print(\"\\n=== LOGGER SERVICE ===\")\n",
    "with open('services/logger.py', 'r') as f:\n",
    "    content = f.read()\n",
    "    lines = content.split('\\n')\n",
    "    for i, line in enumerate(lines[:20]):\n",
    "        print(f\"{i+1:2d}: {line}\")\n",
    "    print(\"...\")\n",
    "\n",
    "print(\"\\n=== UTILITIES ===\")\n",
    "for util_file in ['utils/retry.py', 'utils/communication.py', 'utils/validators.py']:\n",
    "    try:\n",
    "        with open(util_file, 'r') as f:\n",
    "            content = f.read()\n",
    "            lines = content.split('\\n')\n",
    "            print(f\"\\n{util_file}:\")\n",
    "            for i, line in enumerate(lines[:10]):\n",
    "                if line.strip():\n",
    "                    print(f\"  {i+1:2d}: {line}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{util_file} not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Step 13: Advanced Features\n",
    "\n",
    "### Session Management\n",
    "\n",
    "- **Resume Sessions**: Use `--session-id` to continue interrupted workflows\n",
    "- **Session Tracking**: All runs are tracked with unique IDs\n",
    "- **Status Monitoring**: Check session status in database\n",
    "\n",
    "### Parallel Processing\n",
    "\n",
    "- Keyword, Post, and Voice generation run simultaneously\n",
    "- Significant performance improvement over sequential execution\n",
    "- Error handling ensures partial failures don't break the system\n",
    "\n",
    "### Error Handling and Recovery\n",
    "\n",
    "- **Retry Mechanisms**: Automatic retries for API failures\n",
    "- **Fallback Models**: Alternative OpenRouter models if primary fails\n",
    "- **Graceful Degradation**: Continues with partial results\n",
    "- **Comprehensive Logging**: All errors logged with context\n",
    "\n",
    "### API Integration\n",
    "\n",
    "- **OpenRouter API**: Unified access to multiple AI models\n",
    "- **Perplexity AI**: Advanced research capabilities\n",
    "- **Async Operations**: Non-blocking API calls\n",
    "- **Rate Limiting**: Built-in request throttling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show how to use the system programmatically\n",
    "print(\"=== PROGRAMMATIC USAGE EXAMPLE ===\")\n",
    "print('''\n",
    "from agents.master_agent import MasterAgent\n",
    "import asyncio\n",
    "\n",
    "async def generate_content():\n",
    "    async with MasterAgent() as master:\n",
    "        result = await master.process_topic(\"AI in Healthcare\")\n",
    "        print(f\"Post: {result['linkedin_post']}\")\n",
    "        print(f\"Keywords: {result['keywords']}\")\n",
    "        print(f\"Voice script: {result['voice_dialog']}\")\n",
    "\n",
    "# Run the async function\n",
    "asyncio.run(generate_content())\n",
    "''')\n",
    "\n",
    "# Show CLI usage\n",
    "print(\"\\n=== CLI USAGE EXAMPLES ===\")\n",
    "print(\"# Basic usage\")\n",
    "print(\"python main.py \\\"Artificial Intelligence in Healthcare\\\"\")\n",
    "print()\n",
    "print(\"# With verbose logging\")\n",
    "print(\"python main.py \\\"Machine Learning Trends\\\" --verbose\")\n",
    "print()\n",
    "print(\"# Resume a session\")\n",
    "print(\"python main.py \\\"AI Ethics\\\" --session-id 123\")\n",
    "print()\n",
    "print(\"# JSON output\")\n",
    "print(\"python main.py \\\"Blockchain Technology\\\" --output-format json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🆘 Step 14: Troubleshooting\n",
    "\n",
    "### Common Issues\n",
    "\n",
    "1. **OpenRouter API Key Error**\n",
    "   - Ensure API key is correctly set in `.env`\n",
    "   - Check account has sufficient credits\n",
    "   - Verify key permissions\n",
    "\n",
    "2. **Database Connection Error**\n",
    "   - Ensure write permissions in project directory\n",
    "   - Check SQLite installation\n",
    "   - Verify database file integrity\n",
    "\n",
    "3. **Research Failures**\n",
    "   - Check internet connection\n",
    "   - Verify OpenRouter API access\n",
    "   - Some topics may have limited research data\n",
    "\n",
    "4. **Agent Timeouts**\n",
    "   - Increase timeout settings in config\n",
    "   - Check API rate limits\n",
    "   - Reduce concurrent operations\n",
    "\n",
    "### Debug Mode\n",
    "\n",
    "Run with maximum verbosity:\n",
    "```bash\n",
    "python main.py \"Topic\" --verbose\n",
    "```\n",
    "\n",
    "Check logs:\n",
    "- Console output for real-time debugging\n",
    "- `agentic_system.log` for persistent logs\n",
    "- Database tables for detailed execution history\n",
    "\n",
    "### Getting Help\n",
    "\n",
    "- Check the logs in `agentic_system.log`\n",
    "- Review database agent_logs table\n",
    "- Open issues on GitHub\n",
    "- Check OpenRouter API status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for common issues\n",
    "print(\"=== TROUBLESHOOTING CHECKS ===\")\n",
    "\n",
    "# Check Python version\n",
    "import sys\n",
    "version = sys.version_info\n",
    "if version.major >= 3 and version.minor >= 9:\n",
    "    print(\"✓ Python version is compatible\")\n",
    "else:\n",
    "    print(f\"✗ Python version {version.major}.{version.minor} may be too old. Requires 3.9+\")\n",
    "\n",
    "# Check for required files\n",
    "required_files = ['main.py', 'agents/master_agent.py', 'config/settings.py']\n",
    "for file in required_files:\n",
    "    if Path(file).exists():\n",
    "        print(f\"✓ {file} exists\")\n",
    "    else:\n",
    "        print(f\"✗ {file} missing\")\n",
    "\n",
    "# Check imports\n",
    "try:\n",
    "    import asyncio\n",
    "    import dotenv\n",
    "    import click\n",
    "    print(\"✓ Core dependencies available\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ Missing dependency: {e}\")\n",
    "    print(\"Run: pip install -r requirements.txt\")\n",
    "\n",
    "# Check environment\n",
    "from pathlib import Path\n",
    "if Path('.env').exists():\n",
    "    print(\"✓ .env file exists\")\n",
    "    # Check if it has content\n",
    "    with open('.env', 'r') as f:\n",
    "        content = f.read().strip()\n",
    "        if content:\n",
    "            print(\"✓ .env file has content\")\n",
    "        else:\n",
    "            print(\"✗ .env file is empty\")\n",
    "else:\n",
    "    print(\"✗ .env file missing (copy from .env.example)\")\n",
    "\n",
    "print(\"\\n=== SYSTEM INFO ===\")\n",
    "print(f\"Platform: {sys.platform}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Current directory: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📚 Step 15: Code Examples and Customization\n",
    "\n",
    "### Creating a Custom Agent\n",
    "\n",
    "Here's how to create a new agent that extends the system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show how to create a custom agent\n",
    "print(\"=== CUSTOM AGENT TEMPLATE ===\")\n",
    "custom_agent_code = '''\n",
    "from agents.base_agent import BaseAgent\n",
    "from typing import Dict, Any\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class CustomAgent(BaseAgent):\n",
    "    \"\"\"Custom agent for specialized tasks.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"custom_agent\", \"custom\")\n",
    "    \n",
    "    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Execute the custom agent logic.\"\"\"\n",
    "        \n",
    "        self.validate_input(input_data, [\"topic\"])\n",
    "        \n",
    "        topic = input_data[\"topic\"]\n",
    "        logger.info(f\"Custom agent processing topic: {topic}\")\n",
    "        \n",
    "        # Your custom logic here\n",
    "        # For example, generate a summary, analysis, etc.\n",
    "        \n",
    "        result = {\n",
    "            \"topic\": topic,\n",
    "            \"custom_output\": f\"Custom analysis of {topic}\",\n",
    "            \"timestamp\": \"2024-01-01T00:00:00Z\"\n",
    "        }\n",
    "        \n",
    "        # Log the result\n",
    "        await self.log_action(\"custom_processing\", \n",
    "                            input_data=input_data, \n",
    "                            output_data=result)\n",
    "        \n",
    "        return result\n",
    "'''\n",
    "\n",
    "print(custom_agent_code)\n",
    "\n",
    "print(\"\\n=== HOW TO INTEGRATE CUSTOM AGENT ===\")\n",
    "integration_steps = '''\n",
    "1. Save the custom agent in agents/sub_agents/custom_agent.py\n",
    "2. Import it in agents/master_agent.py\n",
    "3. Add it to the sub_agents dictionary in initialize_all_agents()\n",
    "4. Update the parallel execution in process_topic_with_research()\n",
    "5. Add configuration in config/settings.py if needed\n",
    "'''\n",
    "print(integration_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎉 Step 16: Conclusion and Next Steps\n",
    "\n",
    "Congratulations! You've explored the entire Agentic Podcast Generator system. Here's what you've learned:\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **Multi-Agent Architecture**: How specialized agents work together\n",
    "- **Research-First Approach**: Perplexity AI provides comprehensive research\n",
    "- **Parallel Processing**: Content generation happens simultaneously\n",
    "- **Database Persistence**: Logging and session management\n",
    "- **Error Resilience**: Graceful handling of failures\n",
    "- **Model Accuracy**: GPT-5 is NOT used despite some outdated references\n",
    "- **Modular Design**: Easy to extend and customize\n",
    "\n",
    "### What You Can Do Next\n",
    "\n",
    "1. **Run the System**: Try `python main.py \"Your Topic\"`\n",
    "2. **Add Custom Agents**: Extend functionality for your needs\n",
    "3. **Modify Configurations**: Adjust models and parameters\n",
    "4. **Monitor Performance**: Check logs and database\n",
    "5. **Contribute**: Improve the system and share your changes\n",
    "\n",
    "### Resources\n",
    "\n",
    "- **README.md**: Complete documentation\n",
    "- **system_architecture.md**: Detailed technical specs\n",
    "- **tests/**: Examples of how components work\n",
    "- **GitHub Issues**: Report bugs and request features\n",
    "\n",
    "### Important Reminder\n",
    "\n",
    "**GPT-5 is not used in this system.** The actual models are:\n",
    "- Research: Perplexity AI (sonar)\n",
    "- Keywords: Gemini 2.0 Flash\n",
    "- Posts & Voice: Grok-3 Mini\n",
    "\n",
    "Happy coding! 🚀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"=== TUTORIAL SUMMARY ===\")\n",
    "print(\"You have successfully explored:\")\n",
    "print(\"✓ Project structure and organization\")\n",
    "print(\"✓ System architecture and workflow\")\n",
    "print(\"✓ Configuration and setup\")\n",
    "print(\"✓ Agent classes and execution\")\n",
    "print(\"✓ Database schema and models\")\n",
    "print(\"✓ Testing and debugging\")\n",
    "print(\"✓ Customization and extension\")\n",
    "print(\"✓ GPT-5 reference identification\")\n",
    "print()\n",
    "print(\"The Agentic Podcast Generator is ready for your topics!\")\n",
    "print(\"Next: python main.py \\\"Your Favorite Topic\\\"\")\n",
    "print()\n",
    "print(\"Remember: GPT-5 is NOT used - the system uses Perplexity AI, Gemini, and Grok models!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-podcast-generator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
